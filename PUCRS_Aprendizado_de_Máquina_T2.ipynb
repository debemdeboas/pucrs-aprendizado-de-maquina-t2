{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debemdeboas/pucrs-aprendizado-de-maquina-t2/blob/master/PUCRS_Aprendizado_de_M%C3%A1quina_T2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import functional as TF\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "yKqD4YWivM_g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and extract our dataset.\n",
        "\n",
        "This will download a tarred file and extract it into `dist`. Then, we're renaming it to `animes/`.\n",
        "This directory contains the following files:\n",
        "- `animes.csv`, the CSV containing anime IDs, URLs, titles, genres, and poster path\n",
        "- `animes.pkl`, serialized (pickled) list of `Anime` instances. This isn't used by this notebook\n",
        "- `images/`, a directory that contains all of our anime posters as `images/<mal_id>.jpg` files\n"
      ],
      "metadata": {
        "id": "-Sz2tJ-38Ypr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b9ZTAtF86a_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819516f2-dc06-4841-d0c2-a0c420ff18e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-db4d18b46524>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"genres\"] = df[\"genres\"].str.split('|')\n"
          ]
        }
      ],
      "source": [
        "ds = requests.get(\"https://public-s3.debem.dev/anime_dataset.tar.xz\", allow_redirects=True)\n",
        "\n",
        "with open(\"anime_dataset.tar.xz\", \"wb\") as f:\n",
        "    f.write(ds.content)\n",
        "\n",
        "!tar xf anime_dataset.tar.xz\n",
        "\n",
        "df = pd.read_csv(\"animes.csv\")\n",
        "df = df.dropna()\n",
        "df[\"genres\"] = df[\"genres\"].str.split('|')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_genres_to_idx = dict()\n",
        "all_genres = list()\n",
        "for gl in df.genres:\n",
        "    for g in gl:\n",
        "        if g not in all_genres_to_idx:\n",
        "            all_genres.append(g)\n",
        "            all_genres_to_idx[g] = len(all_genres) - 1"
      ],
      "metadata": {
        "id": "yLBqs5DFEC1e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PosterMultiLabelDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, transform=None, *args, **kwargs):\n",
        "        self.df = df\n",
        "        if transform:\n",
        "            self.transform = transform\n",
        "        else:\n",
        "            self.transform = T.Compose([\n",
        "                T.Resize((256,256)),\n",
        "                T.RandomResizedCrop(224),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "                ])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.loc[idx].img_path\n",
        "        img = Image.open(img_path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img), torch.Tensor([1 if g in self.df.loc[idx].genres else 0 for g in all_genres])\n",
        "        # return {\n",
        "        #     \"image\": self.transform(img),\n",
        "        #     \"labels\": torch.Tensor([1 if g in self.df.loc[idx].genres else 0 for g in all_genres])\n",
        "        # }"
      ],
      "metadata": {
        "id": "F9X1yBFZslO5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get some transfer learning done.\n",
        "\n",
        "We'll use a pre-trained convolutional network to analyze the posters to define which genres a given anime belongs to.\n",
        "Each anime can belong to any number of genres.\n"
      ],
      "metadata": {
        "id": "0Z5QkRZL8enF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def validation(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs,labels)\n",
        "            val_loss +=loss\n",
        "    return val_loss/len(loader)\n",
        "\n",
        "\n",
        "def train(model, trainloader, testloader, optimizer, criterion, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for i, (images, labels) in tqdm(enumerate(trainloader)):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        val_loss = validation(model, testloader, criterion)\n",
        "        print(f'Epoch: {epoch+1} | Loss: {running_loss/len(trainloader)} | Val Loss: {val_loss}')\n",
        "\n",
        "\n",
        "def confusion_matrix(model, loader):\n",
        "    model.eval()\n",
        "    confusion_matrix = np.zeros((len(all_genres), len(all_genres)))\n",
        "    with torch.no_grad():\n",
        "        for (img, lbl) in loader:\n",
        "            img = img.to(device)\n",
        "            lbl = lbl.to(device)\n",
        "            output = model(img)\n",
        "            predictions = output > 0.5\n",
        "\n",
        "                # confusion_matrix[idx_true][idx_pred] += int(predictions[i][j].item())\n",
        "\n",
        "            # list(zip(zip(ls[0].tolist(), predictions[0].tolist()), all_genres))\n",
        "\n",
        "            for ll, pp in zip(lbl, predictions):\n",
        "                for i, (l, p) in enumerate(zip(ll, pp)):\n",
        "                    print(all_genres[i], l.item(), p.item())\n",
        "                    break\n",
        "                break\n",
        "\n",
        "\n",
        "                # confusion_matrix[idx_true][idx_pred] += 1\n",
        "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Label')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for (img, lbl) in loader:\n",
        "            img = img.to(device)\n",
        "            lbl = lbl.to(device)\n",
        "            output = model(img)\n",
        "            predictions = output > 0.5\n",
        "            correct += (predictions | (lbl > 0)).sum().item()\n",
        "            total += lbl.shape[0] * lbl.shape[1]\n",
        "    return correct * 100 // total\n"
      ],
      "metadata": {
        "id": "kXodITD1GmMa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "\n",
        "resnet = resnet50(weights = True)\n",
        "resnet.fc = nn.Linear(2048, len(all_genres))\n",
        "for name, params in resnet.named_parameters():\n",
        "    if name not in ('fc.weight', 'fc.bias'):\n",
        "        params.requires_grad = False\n",
        "\n",
        "resnet.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "KmEkiYjHyntS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d75174-af3c-4c09-98bc-f439f6ac5ce7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dados de treino = 70%, validação = 15%, teste = 15%\n",
        "trainData = df.sample(frac = 0.7)\n",
        "trainDataLeftover = df.drop(trainData.index)\n",
        "validationData = trainDataLeftover.sample(frac = 0.5)\n",
        "testData = trainDataLeftover.drop(validationData.index)\n",
        "\n",
        "testData = testData.reset_index()\n",
        "validationData = validationData.reset_index()\n",
        "trainData = trainData.reset_index()"
      ],
      "metadata": {
        "id": "mTxzmlSGxE1s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(PosterMultiLabelDataset(df=trainData), batch_size=4, shuffle=True)\n",
        "testloader = DataLoader(PosterMultiLabelDataset(df=testData), batch_size=4, shuffle=False)\n",
        "valloader = DataLoader(PosterMultiLabelDataset(df=validationData), batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "4llD2deT4dWI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(resnet, trainloader, testloader, optimizer, criterion, epochs)"
      ],
      "metadata": {
        "id": "2MBwVmJmSTS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1024485d-1960-49e0-bf98-b80defe16b1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4248it [05:50, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Loss: 0.1307430973657093 | Val Loss: 0.12884527444839478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4248it [05:40, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | Loss: 0.1282656340160023 | Val Loss: 0.12489526718854904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4248it [05:48, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | Loss: 0.12741508798344015 | Val Loss: 0.12873677909374237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet, 'resnet50.pt')"
      ],
      "metadata": {
        "id": "H9GPqLKEo0xn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'A rede atinge: {accuracy(resnet, valloader)}% de acurácia')"
      ],
      "metadata": {
        "id": "S6vBCpuqAhvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2259e2d-9a2f-49ac-a535-833e460c4394"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A rede atinge: 4% de acurácia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls = [l for l in lbl]\n",
        "list(zip(zip(ls[0].tolist(), predictions[0].tolist()), all_genres))"
      ],
      "metadata": {
        "id": "8acIkhQxUZ1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(resnet, valloader)"
      ],
      "metadata": {
        "id": "4F7XK0kvSNJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}